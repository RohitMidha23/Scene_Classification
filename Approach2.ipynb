{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import argparse\n",
    "# from tensorboardX import SummaryWriter\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SceneDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None, mode='train'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.mode = mode\n",
    "        self.image_frame = pd.read_csv(csv_file)\n",
    "        self.img_name = self.image_frame.image_name\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_name)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(self.root_dir + '/' + self.img_name[idx])\n",
    "        if self.mode == 'train':\n",
    "            label = self.image_frame.iloc[idx].label\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(Image.fromarray(image))\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            return image, label\n",
    "        else:\n",
    "            return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input the Training and Testing Data\n",
    "import cv2\n",
    "train_path = 'train-scene/train'\n",
    "\n",
    "train_dataset = SceneDataset(csv_file='train-scene/train.csv',\n",
    "                                    root_dir=train_path, transform=transforms.Compose([\n",
    "                                               transforms.RandomHorizontalFlip(),\n",
    "#                                                transforms.RandomVerticalFlip(),\n",
    "#                                                transforms.RandomRotation(90),\n",
    "                                               transforms.Resize((224, 224)),\n",
    "                                               transforms.RandomRotation(30),\n",
    "                                               transforms.ToTensor()\n",
    "                                           ]), mode = 'train')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32,\n",
    "                        shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dataset = SceneDataset(csv_file='test.csv', root_dir=train_path, transform=transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()]), mode = 'val')\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32,\n",
    "                        shuffle=False, num_workers=0)\n",
    "\n",
    "validation_split = .15\n",
    "dataset_size = len(train_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "# if shuffle_dataset :\n",
    "#     np.random.seed(random_seed)\n",
    "#     np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, \n",
    "                                           sampler=train_sampler,shuffle=False, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32,\n",
    "                                                sampler=valid_sampler, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 14479, 'val': 2555}\n",
      "533 229 453 80\n"
     ]
    }
   ],
   "source": [
    "dataset_sizes = {'train': len(train_dataset) - split, 'val': split}\n",
    "print (dataset_sizes)\n",
    "print (len(train_dataloader), len(test_dataloader), len(train_loader), len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "n_class = 6\n",
    "kernel_size = (1,1)\n",
    "stride = (1,1)\n",
    "\n",
    "\"\"\" training functions\n",
    "\"\"\"\n",
    "model_conv = torchvision.models.densenet121(pretrained='imagenet')\n",
    "num_ftrs = model_conv.classifier.in_features\n",
    "maxm = 0\n",
    "for i, param in model_conv.named_parameters():\n",
    "    maxm = maxm + 1\n",
    "    if maxm < 182:\n",
    "      param.requires_grad = False\n",
    "print(maxm)\n",
    "model_conv.fc = nn.Sequential(\n",
    "            nn.Linear(512,400),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Conv2d(400,num_ftrs,8),\n",
    "            nn.MaxPool2d(3, 3),\n",
    "            nn.Linear(num_ftrs, 6))\n",
    "model_conv = model_conv.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer_conv = optim.Adam(list(filter(lambda p: p.requires_grad, model_conv.parameters())), lr=5e-4)\n",
    "exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer_conv,mode = 'min', patience=3, factor = 0.5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, dataset_sizes, criterion, optimizer, scheduler, use_gpu, num_epochs=25, mixup = False, alpha = 0.1):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            # get the inputs\n",
    "            for data in tqdm(dataloaders[phase]):\n",
    "                inputs, labels = data\n",
    "                if use_gpu:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                if type(outputs) == tuple:\n",
    "                    outputs, _ = outputs\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = float(running_loss.cpu()) / dataset_sizes[phase]\n",
    "            epoch_acc = float(running_corrects.cpu()) / dataset_sizes[phase]\n",
    "\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                'phase', epoch_loss, epoch_acc))\n",
    "#             print (int(running_corrects.cpu()))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "        scheduler.step(epoch_loss)\n",
    "        for param_group in optimizer.param_groups:\n",
    "          print(param_group['lr'])\n",
    "\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [02:08<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0132 Acc: 0.8699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:13<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0079 Acc: 0.9155\n",
      "0.0005\n",
      "Epoch 1/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [02:12<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0074 Acc: 0.9144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:14<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0080 Acc: 0.9143\n",
      "0.0005\n",
      "Epoch 2/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [02:15<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0061 Acc: 0.9309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:14<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0072 Acc: 0.9256\n",
      "0.0005\n",
      "Epoch 3/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [02:15<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0053 Acc: 0.9382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:14<00:00,  5.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0067 Acc: 0.9366\n",
      "0.0005\n",
      "Epoch 4/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [02:15<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0049 Acc: 0.9424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:15<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0072 Acc: 0.9323\n",
      "0.0005\n",
      "Epoch 5/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [02:15<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0046 Acc: 0.9462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:14<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0071 Acc: 0.9315\n",
      "0.0005\n",
      "Epoch 6/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [02:10<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0042 Acc: 0.9501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:13<00:00,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0073 Acc: 0.9311\n",
      "0.0005\n",
      "Epoch 7/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [02:10<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0036 Acc: 0.9570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:13<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0067 Acc: 0.9354\n",
      "0.0005\n",
      "Epoch 8/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [02:11<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0034 Acc: 0.9601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:13<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0072 Acc: 0.9346\n",
      "0.0005\n",
      "Epoch 9/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [02:10<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0032 Acc: 0.9616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:13<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0076 Acc: 0.9252\n",
      "0.0005\n",
      "Training complete in 24m 27s\n",
      "Best val Acc: 0.936595\n"
     ]
    }
   ],
   "source": [
    "model_conv = train_model(model_conv, {'train':train_loader, 'val':val_loader}, dataset_sizes, criterion, optimizer_conv, exp_lr_scheduler, True,\n",
    "                     num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/80 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "  1%|█                                                                                  | 1/80 [00:00<00:12,  6.15it/s]\n",
      "\n",
      "\n",
      "  2%|██                                                                                 | 2/80 [00:00<00:12,  6.37it/s]\n",
      "\n",
      "\n",
      "  4%|███                                                                                | 3/80 [00:00<00:12,  6.32it/s]\n",
      "\n",
      "\n",
      "  5%|████▏                                                                              | 4/80 [00:00<00:11,  6.45it/s]\n",
      "\n",
      "\n",
      "  6%|█████▏                                                                             | 5/80 [00:00<00:11,  6.57it/s]\n",
      "\n",
      "\n",
      "  8%|██████▏                                                                            | 6/80 [00:00<00:10,  6.74it/s]\n",
      "\n",
      "\n",
      "  9%|███████▎                                                                           | 7/80 [00:01<00:10,  6.67it/s]\n",
      "\n",
      "\n",
      " 10%|████████▎                                                                          | 8/80 [00:01<00:10,  6.66it/s]\n",
      "\n",
      "\n",
      " 11%|█████████▎                                                                         | 9/80 [00:01<00:11,  6.45it/s]\n",
      "\n",
      "\n",
      " 12%|██████████▎                                                                       | 10/80 [00:01<00:11,  6.19it/s]\n",
      "\n",
      "\n",
      " 14%|███████████▎                                                                      | 11/80 [00:01<00:11,  5.99it/s]\n",
      "\n",
      "\n",
      " 15%|████████████▎                                                                     | 12/80 [00:01<00:11,  6.08it/s]\n",
      "\n",
      "\n",
      " 16%|█████████████▎                                                                    | 13/80 [00:02<00:10,  6.32it/s]\n",
      "\n",
      "\n",
      " 18%|██████████████▎                                                                   | 14/80 [00:02<00:10,  6.20it/s]\n",
      "\n",
      "\n",
      " 19%|███████████████▍                                                                  | 15/80 [00:02<00:10,  6.27it/s]\n",
      "\n",
      "\n",
      " 20%|████████████████▍                                                                 | 16/80 [00:02<00:10,  6.30it/s]\n",
      "\n",
      "\n",
      " 21%|█████████████████▍                                                                | 17/80 [00:02<00:09,  6.44it/s]\n",
      "\n",
      "\n",
      " 22%|██████████████████▍                                                               | 18/80 [00:02<00:09,  6.53it/s]\n",
      "\n",
      "\n",
      " 24%|███████████████████▍                                                              | 19/80 [00:02<00:09,  6.66it/s]\n",
      "\n",
      "\n",
      " 25%|████████████████████▌                                                             | 20/80 [00:03<00:09,  6.51it/s]\n",
      "\n",
      "\n",
      " 26%|█████████████████████▌                                                            | 21/80 [00:03<00:08,  6.63it/s]\n",
      "\n",
      "\n",
      " 28%|██████████████████████▌                                                           | 22/80 [00:03<00:08,  6.68it/s]\n",
      "\n",
      "\n",
      " 29%|███████████████████████▌                                                          | 23/80 [00:03<00:08,  6.75it/s]\n",
      "\n",
      "\n",
      " 30%|████████████████████████▌                                                         | 24/80 [00:03<00:08,  6.74it/s]\n",
      "\n",
      "\n",
      " 31%|█████████████████████████▋                                                        | 25/80 [00:03<00:08,  6.82it/s]\n",
      "\n",
      "\n",
      " 32%|██████████████████████████▋                                                       | 26/80 [00:03<00:07,  6.89it/s]\n",
      "\n",
      "\n",
      " 34%|███████████████████████████▋                                                      | 27/80 [00:04<00:07,  6.93it/s]\n",
      "\n",
      "\n",
      " 35%|████████████████████████████▋                                                     | 28/80 [00:04<00:07,  6.80it/s]\n",
      "\n",
      "\n",
      " 36%|█████████████████████████████▋                                                    | 29/80 [00:04<00:07,  6.80it/s]\n",
      "\n",
      "\n",
      " 38%|██████████████████████████████▊                                                   | 30/80 [00:04<00:07,  6.75it/s]\n",
      "\n",
      "\n",
      " 39%|███████████████████████████████▊                                                  | 31/80 [00:04<00:07,  6.48it/s]\n",
      "\n",
      "\n",
      " 40%|████████████████████████████████▊                                                 | 32/80 [00:04<00:07,  6.60it/s]\n",
      "\n",
      "\n",
      " 41%|█████████████████████████████████▊                                                | 33/80 [00:05<00:07,  6.65it/s]\n",
      "\n",
      "\n",
      " 42%|██████████████████████████████████▊                                               | 34/80 [00:05<00:06,  6.63it/s]\n",
      "\n",
      "\n",
      " 44%|███████████████████████████████████▉                                              | 35/80 [00:05<00:06,  6.62it/s]\n",
      "\n",
      "\n",
      " 45%|████████████████████████████████████▉                                             | 36/80 [00:05<00:06,  6.68it/s]\n",
      "\n",
      "\n",
      " 46%|█████████████████████████████████████▉                                            | 37/80 [00:05<00:06,  6.71it/s]\n",
      "\n",
      "\n",
      " 48%|██████████████████████████████████████▉                                           | 38/80 [00:05<00:06,  6.78it/s]\n",
      "\n",
      "\n",
      " 49%|███████████████████████████████████████▉                                          | 39/80 [00:05<00:06,  6.79it/s]\n",
      "\n",
      "\n",
      " 50%|█████████████████████████████████████████                                         | 40/80 [00:06<00:05,  6.75it/s]\n",
      "\n",
      "\n",
      " 51%|██████████████████████████████████████████                                        | 41/80 [00:06<00:05,  6.77it/s]\n",
      "\n",
      "\n",
      " 52%|███████████████████████████████████████████                                       | 42/80 [00:06<00:05,  6.78it/s]\n",
      "\n",
      "\n",
      " 54%|████████████████████████████████████████████                                      | 43/80 [00:06<00:05,  6.47it/s]\n",
      "\n",
      "\n",
      " 55%|█████████████████████████████████████████████                                     | 44/80 [00:06<00:05,  6.32it/s]\n",
      "\n",
      "\n",
      " 56%|██████████████████████████████████████████████▏                                   | 45/80 [00:06<00:05,  6.20it/s]\n",
      "\n",
      "\n",
      " 57%|███████████████████████████████████████████████▏                                  | 46/80 [00:07<00:05,  6.20it/s]\n",
      "\n",
      "\n",
      " 59%|████████████████████████████████████████████████▏                                 | 47/80 [00:07<00:05,  6.25it/s]\n",
      "\n",
      "\n",
      " 60%|█████████████████████████████████████████████████▏                                | 48/80 [00:07<00:05,  6.29it/s]\n",
      "\n",
      "\n",
      " 61%|██████████████████████████████████████████████████▏                               | 49/80 [00:07<00:04,  6.26it/s]\n",
      "\n",
      "\n",
      " 62%|███████████████████████████████████████████████████▎                              | 50/80 [00:07<00:04,  6.29it/s]\n",
      "\n",
      "\n",
      " 64%|████████████████████████████████████████████████████▎                             | 51/80 [00:07<00:04,  6.47it/s]\n",
      "\n",
      "\n",
      " 65%|█████████████████████████████████████████████████████▎                            | 52/80 [00:07<00:04,  6.49it/s]\n",
      "\n",
      "\n",
      " 66%|██████████████████████████████████████████████████████▎                           | 53/80 [00:08<00:04,  6.56it/s]\n",
      "\n",
      "\n",
      " 68%|███████████████████████████████████████████████████████▎                          | 54/80 [00:08<00:03,  6.59it/s]\n",
      "\n",
      "\n",
      " 69%|████████████████████████████████████████████████████████▍                         | 55/80 [00:08<00:03,  6.54it/s]\n",
      "\n",
      "\n",
      " 70%|█████████████████████████████████████████████████████████▍                        | 56/80 [00:08<00:03,  6.55it/s]\n",
      "\n",
      "\n",
      " 71%|██████████████████████████████████████████████████████████▍                       | 57/80 [00:08<00:03,  6.68it/s]\n",
      "\n",
      "\n",
      " 72%|███████████████████████████████████████████████████████████▍                      | 58/80 [00:08<00:03,  6.75it/s]\n",
      "\n",
      "\n",
      " 74%|████████████████████████████████████████████████████████████▍                     | 59/80 [00:09<00:03,  6.68it/s]\n",
      "\n",
      "\n",
      " 75%|█████████████████████████████████████████████████████████████▌                    | 60/80 [00:09<00:03,  6.66it/s]\n",
      "\n",
      "\n",
      " 76%|██████████████████████████████████████████████████████████████▌                   | 61/80 [00:09<00:02,  6.63it/s]\n",
      "\n",
      "\n",
      " 78%|███████████████████████████████████████████████████████████████▌                  | 62/80 [00:09<00:02,  6.52it/s]\n",
      "\n",
      "\n",
      " 79%|████████████████████████████████████████████████████████████████▌                 | 63/80 [00:09<00:02,  6.49it/s]\n",
      "\n",
      "\n",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 64/80 [00:09<00:02,  6.53it/s]\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████████████████████████████████████████▋               | 65/80 [00:09<00:02,  6.51it/s]\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████████████████████████████████████████▋              | 66/80 [00:10<00:02,  6.56it/s]\n",
      "\n",
      "\n",
      " 84%|████████████████████████████████████████████████████████████████████▋             | 67/80 [00:10<00:01,  6.69it/s]\n",
      "\n",
      "\n",
      " 85%|█████████████████████████████████████████████████████████████████████▋            | 68/80 [00:10<00:01,  6.53it/s]\n",
      "\n",
      "\n",
      " 86%|██████████████████████████████████████████████████████████████████████▋           | 69/80 [00:10<00:01,  6.54it/s]\n",
      "\n",
      "\n",
      " 88%|███████████████████████████████████████████████████████████████████████▊          | 70/80 [00:10<00:01,  6.42it/s]\n",
      "\n",
      "\n",
      " 89%|████████████████████████████████████████████████████████████████████████▊         | 71/80 [00:10<00:01,  6.57it/s]\n",
      "\n",
      "\n",
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 72/80 [00:10<00:01,  6.74it/s]\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████████████████████████████████████████████▊       | 73/80 [00:11<00:01,  6.78it/s]\n",
      "\n",
      "\n",
      " 92%|███████████████████████████████████████████████████████████████████████████▊      | 74/80 [00:11<00:00,  6.82it/s]\n",
      "\n",
      "\n",
      " 94%|████████████████████████████████████████████████████████████████████████████▉     | 75/80 [00:11<00:00,  6.82it/s]\n",
      "\n",
      "\n",
      " 95%|█████████████████████████████████████████████████████████████████████████████▉    | 76/80 [00:11<00:00,  6.81it/s]\n",
      "\n",
      "\n",
      " 96%|██████████████████████████████████████████████████████████████████████████████▉   | 77/80 [00:11<00:00,  6.62it/s]\n",
      "\n",
      "\n",
      " 98%|███████████████████████████████████████████████████████████████████████████████▉  | 78/80 [00:11<00:00,  6.63it/s]\n",
      "\n",
      "\n",
      " 99%|████████████████████████████████████████████████████████████████████████████████▉ | 79/80 [00:12<00:00,  6.68it/s]\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:12<00:00,  6.79it/s]"
     ]
    }
   ],
   "source": [
    "def test_model(model, dataloaders, optimizer, use_gpu):\n",
    "    model.train(False)\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    for data in tqdm(dataloaders):\n",
    "        inputs, labels_ = data\n",
    "        if use_gpu:\n",
    "            inputs = Variable(inputs.cuda())\n",
    "        else:\n",
    "            inputs = Variable(inputs)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        predictions.append(preds)\n",
    "        labels.append(labels_)\n",
    "\n",
    "    return predictions, labels\n",
    "  \n",
    "predictions, labels = test_model(model_conv, val_loader, optimizer_conv, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_path = 'C:\\Users\\rohit\\VirtualEnv'\n",
    "torch.save(model_conv.state_dict(), 'densenet121_sequential.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1, labels1 = torch.cat(predictions), torch.cat(labels)\n",
    "predictions1, labels1 = np.array(predictions1.cpu()), np.array(labels1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 0, ..., 5, 5, 4], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 0, ..., 5, 5, 4], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2555"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test1_model(model, dataloaders, optimizer, use_gpu):\n",
    "    model.train(False)\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    for data in tqdm(dataloaders):\n",
    "        inputs = data\n",
    "        if use_gpu:\n",
    "            inputs = Variable(inputs.cuda())\n",
    "        else:\n",
    "            inputs = Variable(inputs)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        predictions.append(preds)\n",
    "        #labels.append(labels_)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 229/229 [00:32<00:00,  7.45it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions2 = test1_model(model_conv, test_dataloader, optimizer_conv, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions3 = torch.cat(predictions2)\n",
    "predictions3 = np.array(predictions3.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7301"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 2, 5], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions3[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv('resnet50_15_col.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7301"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['label'] = predictions3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name  label\n",
       "0      3.jpg      5\n",
       "1      5.jpg      0\n",
       "2      6.jpg      4\n",
       "3     11.jpg      2\n",
       "4     14.jpg      5"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('torch_densenet121_sequential.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import argparse\n",
    "# from tensorboardX import SummaryWriter\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SceneDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None, mode='train'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.mode = mode\n",
    "        self.image_frame = pd.read_csv(csv_file)\n",
    "        self.img_name = self.image_frame.image_name\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_name)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(self.root_dir + '/' + self.img_name[idx])\n",
    "        if self.mode == 'train':\n",
    "            label = self.image_frame.iloc[idx].label\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(Image.fromarray(image))\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            return image, label\n",
    "        else:\n",
    "            return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input the Training and Testing Data\n",
    "import cv2\n",
    "train_path = 'train-scene/train'\n",
    "\n",
    "train_dataset = SceneDataset(csv_file='train-scene/train.csv',\n",
    "                                    root_dir=train_path, transform=transforms.Compose([\n",
    "                                               transforms.RandomHorizontalFlip(),\n",
    "#                                                transforms.RandomVerticalFlip(),\n",
    "#                                                transforms.RandomRotation(90),\n",
    "                                               transforms.Resize((224, 224)),\n",
    "                                               transforms.RandomRotation(30),\n",
    "                                               transforms.ToTensor()\n",
    "                                           ]), mode = 'train')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32,\n",
    "                        shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dataset = SceneDataset(csv_file='test.csv', root_dir=train_path, transform=transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()]), mode = 'val')\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32,\n",
    "                        shuffle=False, num_workers=0)\n",
    "\n",
    "validation_split = .15\n",
    "dataset_size = len(train_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "# if shuffle_dataset :\n",
    "#     np.random.seed(random_seed)\n",
    "#     np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, \n",
    "                                           sampler=train_sampler,shuffle=False, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32,\n",
    "                                                sampler=valid_sampler, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 14479, 'val': 2555}\n",
      "533 229 453 80\n"
     ]
    }
   ],
   "source": [
    "dataset_sizes = {'train': len(train_dataset) - split, 'val': split}\n",
    "print (dataset_sizes)\n",
    "print (len(train_dataloader), len(test_dataloader), len(train_loader), len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "n_class = 6\n",
    "kernel_size = (1,1)\n",
    "stride = (1,1)\n",
    "\n",
    "\"\"\" training functions\n",
    "\"\"\"\n",
    "model_conv = torchvision.models.resnet101(pretrained='imagenet')\n",
    "#num_ftrs = model_conv.classifier.in_features\n",
    "#maxm = 0\n",
    "#for i, param in model_conv.named_parameters():\n",
    "#    maxm = maxm + 1\n",
    "#    if maxm < 182:\n",
    "#      param.requires_grad = False\n",
    "#print(maxm)\n",
    "#model_conv.classifier = nn.Linear(num_ftrs, 6)\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxm = 0\n",
    "for param in model_conv.parameters():\n",
    "    maxm = maxm+1\n",
    "    if maxm < 135:\n",
    "        param.requires_grad = False\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 6)\n",
    "model_conv = model_conv.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer_conv = optim.Adam(list(filter(lambda p: p.requires_grad, model_conv.parameters())), lr=5e-4)\n",
    "exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer_conv,mode = 'min', patience=3, factor = 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, dataset_sizes, criterion, optimizer, scheduler, use_gpu, num_epochs=25, mixup = False, alpha = 0.1):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            # get the inputs\n",
    "            for data in tqdm(dataloaders[phase]):\n",
    "                inputs, labels = data\n",
    "                if use_gpu:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                if type(outputs) == tuple:\n",
    "                    outputs, _ = outputs\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = float(running_loss.cpu()) / dataset_sizes[phase]\n",
    "            epoch_acc = float(running_corrects.cpu()) / dataset_sizes[phase]\n",
    "\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                'phase', epoch_loss, epoch_acc))\n",
    "#             print (int(running_corrects.cpu()))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "        scheduler.step(epoch_loss)\n",
    "        for param_group in optimizer.param_groups:\n",
    "          print(param_group['lr'])\n",
    "\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [03:21<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0058 Acc: 0.9333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:13<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0080 Acc: 0.9205\n",
      "0.0005\n",
      "Epoch 1/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [03:24<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0050 Acc: 0.9421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:13<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0066 Acc: 0.9311\n",
      "0.0005\n",
      "Epoch 2/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [03:22<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0048 Acc: 0.9453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:13<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0069 Acc: 0.9252\n",
      "0.0005\n",
      "Epoch 3/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [03:22<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0046 Acc: 0.9462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:13<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0090 Acc: 0.9135\n",
      "0.00025\n",
      "Epoch 4/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [03:22<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0030 Acc: 0.9650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:13<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0068 Acc: 0.9339\n",
      "0.00025\n",
      "Epoch 5/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [03:22<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0024 Acc: 0.9736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:13<00:00,  5.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0074 Acc: 0.9374\n",
      "0.00025\n",
      "Epoch 6/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [03:22<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0024 Acc: 0.9721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:13<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0076 Acc: 0.9307\n",
      "0.00025\n",
      "Epoch 7/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [03:22<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0020 Acc: 0.9779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:13<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0074 Acc: 0.9370\n",
      "0.000125\n",
      "Epoch 8/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [03:23<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0013 Acc: 0.9858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:13<00:00,  5.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0075 Acc: 0.9358\n",
      "0.000125\n",
      "Epoch 9/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [03:22<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0009 Acc: 0.9891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:13<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0082 Acc: 0.9307\n",
      "0.000125\n",
      "Epoch 10/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [03:21<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0009 Acc: 0.9901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:13<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0091 Acc: 0.9260\n",
      "0.000125\n",
      "Epoch 11/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [03:23<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0009 Acc: 0.9897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:13<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0096 Acc: 0.9311\n",
      "6.25e-05\n",
      "Epoch 12/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [03:23<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0006 Acc: 0.9936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:13<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0094 Acc: 0.9331\n",
      "6.25e-05\n",
      "Epoch 13/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [03:21<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0004 Acc: 0.9963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:13<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0100 Acc: 0.9346\n",
      "6.25e-05\n",
      "Epoch 14/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [03:21<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0004 Acc: 0.9951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:13<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0102 Acc: 0.9362\n",
      "6.25e-05\n",
      "Epoch 15/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [03:21<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0004 Acc: 0.9960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:13<00:00,  5.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0099 Acc: 0.9386\n",
      "3.125e-05\n",
      "Epoch 16/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [03:23<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0003 Acc: 0.9974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:13<00:00,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0104 Acc: 0.9350\n",
      "3.125e-05\n",
      "Epoch 17/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [03:22<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0003 Acc: 0.9972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:13<00:00,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0103 Acc: 0.9374\n",
      "3.125e-05\n",
      "Epoch 18/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [03:21<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0003 Acc: 0.9978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:13<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0101 Acc: 0.9374\n",
      "3.125e-05\n",
      "Epoch 19/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [03:22<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0003 Acc: 0.9977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:13<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0099 Acc: 0.9409\n",
      "1.5625e-05\n",
      "Epoch 20/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [03:22<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0002 Acc: 0.9980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:13<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0105 Acc: 0.9362\n",
      "1.5625e-05\n",
      "Epoch 21/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [03:22<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0002 Acc: 0.9983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:13<00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0105 Acc: 0.9393\n",
      "1.5625e-05\n",
      "Epoch 22/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [03:21<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0002 Acc: 0.9982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:13<00:00,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0098 Acc: 0.9362\n",
      "1.5625e-05\n",
      "Epoch 23/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [03:23<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0002 Acc: 0.9981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:13<00:00,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0101 Acc: 0.9378\n",
      "7.8125e-06\n",
      "Epoch 24/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [03:21<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0002 Acc: 0.9982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:13<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0108 Acc: 0.9386\n",
      "7.8125e-06\n",
      "Training complete in 90m 3s\n",
      "Best val Acc: 0.940900\n"
     ]
    }
   ],
   "source": [
    "model_conv = train_model(model_conv, {'train':train_loader, 'val':val_loader}, dataset_sizes, criterion, optimizer_conv, exp_lr_scheduler, True,\n",
    "                     num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_path = 'C:\\Users\\rohit\\VirtualEnv'\n",
    "torch.save(model_conv.state_dict(), 'resnet101.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test1_model(model, dataloaders, optimizer, use_gpu):\n",
    "    model.train(False)\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    for data in tqdm(dataloaders):\n",
    "        inputs = data\n",
    "        if use_gpu:\n",
    "            inputs = Variable(inputs.cuda())\n",
    "        else:\n",
    "            inputs = Variable(inputs)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        predictions.append(preds)\n",
    "        #labels.append(labels_)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 229/229 [00:35<00:00,  4.73it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions2 = test1_model(model_conv, test_dataloader, optimizer_conv, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions3 = torch.cat(predictions2)\n",
    "predictions3 = np.array(predictions3.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7301"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 4, 5], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions3[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv('resnet50_15_col.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7301"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['label'] = predictions3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name  label\n",
       "0      3.jpg      5\n",
       "1      5.jpg      0\n",
       "2      6.jpg      4\n",
       "3     11.jpg      4\n",
       "4     14.jpg      5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('torch_resnet101.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import argparse\n",
    "# from tensorboardX import SummaryWriter\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SceneDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None, mode='train'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.mode = mode\n",
    "        self.image_frame = pd.read_csv(csv_file)\n",
    "        self.img_name = self.image_frame.image_name\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_name)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(self.root_dir + '/' + self.img_name[idx])\n",
    "        if self.mode == 'train':\n",
    "            label = self.image_frame.iloc[idx].label\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(Image.fromarray(image))\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            return image, label\n",
    "        else:\n",
    "            return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input the Training and Testing Data\n",
    "import cv2\n",
    "train_path = 'train-scene/train'\n",
    "\n",
    "train_dataset = SceneDataset(csv_file='train-scene/train.csv',\n",
    "                                    root_dir=train_path, transform=transforms.Compose([\n",
    "                                               transforms.RandomHorizontalFlip(),\n",
    "#                                                transforms.RandomVerticalFlip(),\n",
    "#                                                transforms.RandomRotation(90),\n",
    "                                               transforms.Resize((224, 224)),\n",
    "                                               transforms.RandomRotation(30),\n",
    "                                               transforms.ToTensor()\n",
    "                                           ]), mode = 'train')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32,\n",
    "                        shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dataset = SceneDataset(csv_file='test.csv', root_dir=train_path, transform=transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()]), mode = 'val')\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32,\n",
    "                        shuffle=False, num_workers=0)\n",
    "\n",
    "validation_split = .15\n",
    "dataset_size = len(train_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "# if shuffle_dataset :\n",
    "#     np.random.seed(random_seed)\n",
    "#     np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, \n",
    "                                           sampler=train_sampler,shuffle=False, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32,\n",
    "                                                sampler=valid_sampler, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 14479, 'val': 2555}\n",
      "533 229 453 80\n"
     ]
    }
   ],
   "source": [
    "dataset_sizes = {'train': len(train_dataset) - split, 'val': split}\n",
    "print (dataset_sizes)\n",
    "print (len(train_dataloader), len(test_dataloader), len(train_loader), len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "n_class = 6\n",
    "kernel_size = (1,1)\n",
    "stride = (1,1)\n",
    "\n",
    "\"\"\" training functions\n",
    "\"\"\"\n",
    "model_conv = torchvision.models.resnet152(pretrained='imagenet')\n",
    "#num_ftrs = model_conv.classifier.in_features\n",
    "#maxm = 0\n",
    "#for i, param in model_conv.named_parameters():\n",
    "#    maxm = maxm + 1\n",
    "#    if maxm < 182:\n",
    "#      param.requires_grad = False\n",
    "#print(maxm)\n",
    "#model_conv.classifier = nn.Linear(num_ftrs, 6)\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467\n"
     ]
    }
   ],
   "source": [
    "maxm = 0\n",
    "for param in model_conv.parameters():\n",
    "    maxm = maxm+1\n",
    "print(maxm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxm = 0\n",
    "for param in model_conv.parameters():\n",
    "    maxm = maxm+1\n",
    "    if maxm < 445:\n",
    "        param.requires_grad = False\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 6)\n",
    "model_conv = model_conv.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer_conv = optim.Adam(list(filter(lambda p: p.requires_grad, model_conv.parameters())), lr=5e-4)\n",
    "exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer_conv,mode = 'min', patience=3, factor = 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, dataset_sizes, criterion, optimizer, scheduler, use_gpu, num_epochs=25, mixup = False, alpha = 0.1):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            # get the inputs\n",
    "            for data in tqdm(dataloaders[phase]):\n",
    "                inputs, labels = data\n",
    "                if use_gpu:\n",
    "                    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                if type(outputs) == tuple:\n",
    "                    outputs, _ = outputs\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = float(running_loss.cpu()) / dataset_sizes[phase]\n",
    "            epoch_acc = float(running_corrects.cpu()) / dataset_sizes[phase]\n",
    "\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                'phase', epoch_loss, epoch_acc))\n",
    "#             print (int(running_corrects.cpu()))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "        scheduler.step(epoch_loss)\n",
    "        for param_group in optimizer.param_groups:\n",
    "          print(param_group['lr'])\n",
    "\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [01:54<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0053 Acc: 0.9391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:17<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0078 Acc: 0.9162\n",
      "0.0005\n",
      "Epoch 1/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [01:55<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0051 Acc: 0.9405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:17<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0070 Acc: 0.9303\n",
      "0.0005\n",
      "Epoch 2/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [01:55<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0045 Acc: 0.9488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:17<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0072 Acc: 0.9295\n",
      "0.0005\n",
      "Epoch 3/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [01:55<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0041 Acc: 0.9519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:17<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0071 Acc: 0.9284\n",
      "0.0005\n",
      "Epoch 4/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [01:56<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0040 Acc: 0.9543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:17<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0068 Acc: 0.9319\n",
      "0.0005\n",
      "Training complete in 11m 5s\n",
      "Best val Acc: 0.931898\n"
     ]
    }
   ],
   "source": [
    "model_conv = train_model(model_conv, {'train':train_loader, 'val':val_loader}, dataset_sizes, criterion, optimizer_conv, exp_lr_scheduler, True,\n",
    "                     num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_path = 'C:\\Users\\rohit\\VirtualEnv'\n",
    "torch.save(model_conv.state_dict(), 'resnet152.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test1_model(model, dataloaders, optimizer, use_gpu):\n",
    "    model.train(False)\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    for data in tqdm(dataloaders):\n",
    "        inputs = data\n",
    "        if use_gpu:\n",
    "            inputs = Variable(inputs.cuda())\n",
    "        else:\n",
    "            inputs = Variable(inputs)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        predictions.append(preds)\n",
    "        #labels.append(labels_)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 229/229 [00:48<00:00,  4.56it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions2 = test1_model(model_conv, test_dataloader, optimizer_conv, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions3 = torch.cat(predictions2)\n",
    "predictions3 = np.array(predictions3.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7301"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 2, 5], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions3[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv('resnet50_15_col.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7301"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['label'] = predictions3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name  label\n",
       "0      3.jpg      5\n",
       "1      5.jpg      0\n",
       "2      6.jpg      4\n",
       "3     11.jpg      4\n",
       "4     14.jpg      5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('torch_resnet152.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Densenet169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import argparse\n",
    "# from tensorboardX import SummaryWriter\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SceneDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None, mode='train'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.mode = mode\n",
    "        self.image_frame = pd.read_csv(csv_file)\n",
    "        self.img_name = self.image_frame.image_name\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_name)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(self.root_dir + '/' + self.img_name[idx])\n",
    "        if self.mode == 'train':\n",
    "            label = self.image_frame.iloc[idx].label\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(Image.fromarray(image))\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            return image, label\n",
    "        else:\n",
    "            return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input the Training and Testing Data\n",
    "import cv2\n",
    "train_path = 'train-scene/train'\n",
    "\n",
    "train_dataset = SceneDataset(csv_file='train-scene/train.csv',\n",
    "                                    root_dir=train_path, transform=transforms.Compose([\n",
    "                                               transforms.RandomHorizontalFlip(),\n",
    "#                                                transforms.RandomVerticalFlip(),\n",
    "#                                                transforms.RandomRotation(90),\n",
    "                                               transforms.Resize((224, 224)),\n",
    "                                               transforms.RandomRotation(30),\n",
    "                                               transforms.ToTensor()\n",
    "                                           ]), mode = 'train')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32,\n",
    "                        shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dataset = SceneDataset(csv_file='test.csv', root_dir=train_path, transform=transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()]), mode = 'val')\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32,\n",
    "                        shuffle=False, num_workers=0)\n",
    "\n",
    "validation_split = .15\n",
    "dataset_size = len(train_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "# if shuffle_dataset :\n",
    "#     np.random.seed(random_seed)\n",
    "#     np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, \n",
    "                                           sampler=train_sampler,shuffle=False, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32,\n",
    "                                                sampler=valid_sampler, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 14479, 'val': 2555}\n",
      "533 229 453 80\n"
     ]
    }
   ],
   "source": [
    "dataset_sizes = {'train': len(train_dataset) - split, 'val': split}\n",
    "print (dataset_sizes)\n",
    "print (len(train_dataloader), len(test_dataloader), len(train_loader), len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rohit\\virtualenv\\lib\\site-packages\\torchvision\\models\\densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n",
      "Downloading: \"https://download.pytorch.org/models/densenet169-b2777c0a.pth\" to C:\\Users\\rohit/.torch\\models\\densenet169-b2777c0a.pth\n",
      "57365526it [00:48, 1183761.48it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "n_class = 6\n",
    "kernel_size = (1,1)\n",
    "stride = (1,1)\n",
    "\n",
    "\"\"\" training functions\n",
    "\"\"\"\n",
    "model_conv = torchvision.models.densenet169(pretrained='imagenet')\n",
    "#num_ftrs = model_conv.classifier.in_features\n",
    "#maxm = 0\n",
    "#for i, param in model_conv.named_parameters():\n",
    "#    maxm = maxm + 1\n",
    "#    if maxm < 182:\n",
    "#      param.requires_grad = False\n",
    "#print(maxm)\n",
    "#model_conv.classifier = nn.Linear(num_ftrs, 6)\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508\n"
     ]
    }
   ],
   "source": [
    "maxm = 0\n",
    "for param in model_conv.parameters():\n",
    "    maxm = maxm+1\n",
    "print(maxm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxm = 0\n",
    "for param in model_conv.parameters():\n",
    "    maxm = maxm+1\n",
    "    if maxm < 470:\n",
    "        param.requires_grad = False\n",
    "num_ftrs = model_conv.classifier.in_features\n",
    "model_conv.classifier = nn.Linear(num_ftrs, 6)\n",
    "model_conv = model_conv.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer_conv = optim.Adam(list(filter(lambda p: p.requires_grad, model_conv.parameters())), lr=5e-4)\n",
    "exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer_conv,mode = 'min', patience=3, factor = 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, dataset_sizes, criterion, optimizer, scheduler, use_gpu, num_epochs=25, mixup = False, alpha = 0.1):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            # get the inputs\n",
    "            for data in tqdm(dataloaders[phase]):\n",
    "                inputs, labels = data\n",
    "                if use_gpu:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                if type(outputs) == tuple:\n",
    "                    outputs, _ = outputs\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = float(running_loss.cpu()) / dataset_sizes[phase]\n",
    "            epoch_acc = float(running_corrects.cpu()) / dataset_sizes[phase]\n",
    "\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                'phase', epoch_loss, epoch_acc))\n",
    "#             print (int(running_corrects.cpu()))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "        scheduler.step(epoch_loss)\n",
    "        for param_group in optimizer.param_groups:\n",
    "          print(param_group['lr'])\n",
    "\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/2\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [01:29<00:00,  5.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0527 Acc: 0.3683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:12<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0484 Acc: 0.5499\n",
      "5e-06\n",
      "Epoch 1/2\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [01:30<00:00,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0455 Acc: 0.6514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:13<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0418 Acc: 0.7695\n",
      "5e-06\n",
      "Epoch 2/2\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [01:30<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0395 Acc: 0.8158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:13<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0358 Acc: 0.8575\n",
      "5e-06\n",
      "Training complete in 5m 11s\n",
      "Best val Acc: 0.857534\n"
     ]
    }
   ],
   "source": [
    "model_conv = train_model(model_conv, {'train':train_loader, 'val':val_loader}, dataset_sizes, criterion, optimizer_conv, exp_lr_scheduler, True,\n",
    "                     num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_path = 'C:\\Users\\rohit\\VirtualEnv'\n",
    "torch.save(model_conv.state_dict(), 'densenet169.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test1_model(model, dataloaders, optimizer, use_gpu):\n",
    "    model.train(False)\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    for data in tqdm(dataloaders):\n",
    "        inputs = data\n",
    "        if use_gpu:\n",
    "            inputs = Variable(inputs.cuda())\n",
    "        else:\n",
    "            inputs = Variable(inputs)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        predictions.append(preds)\n",
    "        #labels.append(labels_)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 229/229 [00:33<00:00,  7.22it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions2 = test1_model(model_conv, test_dataloader, optimizer_conv, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions3 = torch.cat(predictions2)\n",
    "predictions3 = np.array(predictions3.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7301"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 4, 5], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions3[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv('resnet50_15_col.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7301"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['label'] = predictions3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name  label\n",
       "0      3.jpg      5\n",
       "1      5.jpg      0\n",
       "2      6.jpg      4\n",
       "3     11.jpg      4\n",
       "4     14.jpg      5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('torch_densenet169.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SqueezeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import argparse\n",
    "# from tensorboardX import SummaryWriter\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SceneDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None, mode='train'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.mode = mode\n",
    "        self.image_frame = pd.read_csv(csv_file)\n",
    "        self.img_name = self.image_frame.image_name\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_name)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(self.root_dir + '/' + self.img_name[idx])\n",
    "        if self.mode == 'train':\n",
    "            label = self.image_frame.iloc[idx].label\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(Image.fromarray(image))\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            return image, label\n",
    "        else:\n",
    "            return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input the Training and Testing Data\n",
    "import cv2\n",
    "train_path = 'train-scene/train'\n",
    "\n",
    "train_dataset = SceneDataset(csv_file='train-scene/train.csv',\n",
    "                                    root_dir=train_path, transform=transforms.Compose([\n",
    "                                               transforms.RandomHorizontalFlip(),\n",
    "#                                                transforms.RandomVerticalFlip(),\n",
    "#                                                transforms.RandomRotation(90),\n",
    "                                               transforms.Resize((224, 224)),\n",
    "                                               transforms.RandomRotation(30),\n",
    "                                               transforms.ToTensor()\n",
    "                                           ]), mode = 'train')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32,\n",
    "                        shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dataset = SceneDataset(csv_file='test.csv', root_dir=train_path, transform=transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()]), mode = 'val')\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32,\n",
    "                        shuffle=False, num_workers=0)\n",
    "\n",
    "validation_split = .15\n",
    "dataset_size = len(train_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "# if shuffle_dataset :\n",
    "#     np.random.seed(random_seed)\n",
    "#     np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, \n",
    "                                           sampler=train_sampler,shuffle=False, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32,\n",
    "                                                sampler=valid_sampler, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 14479, 'val': 2555}\n",
      "533 229 453 80\n"
     ]
    }
   ],
   "source": [
    "dataset_sizes = {'train': len(train_dataset) - split, 'val': split}\n",
    "print (dataset_sizes)\n",
    "print (len(train_dataloader), len(test_dataloader), len(train_loader), len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth\" to C:\\Users\\rohit/.torch\\models\\squeezenet1_1-f364aa15.pth\n",
      "4966400it [00:02, 2388291.88it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "n_class = 6\n",
    "kernel_size = (1,1)\n",
    "stride = (1,1)\n",
    "\n",
    "\"\"\" training functions\n",
    "\"\"\"\n",
    "model_conv = torchvision.models.squeezenet1_1(True)\n",
    "#num_ftrs = model_conv.classifier.in_features\n",
    "#maxm = 0\n",
    "#for i, param in model_conv.named_parameters():\n",
    "#    maxm = maxm + 1\n",
    "#    if maxm < 182:\n",
    "#      param.requires_grad = False\n",
    "#print(maxm)\n",
    "#model_conv.classifier = nn.Linear(num_ftrs, 6)\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "maxm = 0\n",
    "for param in model_conv.parameters():\n",
    "    maxm = maxm+1\n",
    "print(maxm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'in_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-9787095af14f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmaxm\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mnum_ftrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_conv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mmodel_conv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_ftrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmodel_conv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_conv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rohit\\virtualenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    533\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[1;32m--> 535\u001b[1;33m             type(self).__name__, name))\n\u001b[0m\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'in_features'"
     ]
    }
   ],
   "source": [
    "maxm = 0\n",
    "for param in model_conv.parameters():\n",
    "    maxm = maxm+1\n",
    "    if maxm < 30:\n",
    "        param.requires_grad = False\n",
    "num_ftrs = model_conv.classifier.in_features\n",
    "model_conv.classifier = nn.Linear(num_ftrs, 6)\n",
    "model_conv = model_conv.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer_conv = optim.Adam(list(filter(lambda p: p.requires_grad, model_conv.parameters())), lr=5e-4)\n",
    "exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer_conv,mode = 'min', patience=3, factor = 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, dataset_sizes, criterion, optimizer, scheduler, use_gpu, num_epochs=25, mixup = False, alpha = 0.1):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            # get the inputs\n",
    "            for data in tqdm(dataloaders[phase]):\n",
    "                inputs, labels = data\n",
    "                if use_gpu:\n",
    "                    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                if type(outputs) == tuple:\n",
    "                    outputs, _ = outputs\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = float(running_loss.cpu()) / dataset_sizes[phase]\n",
    "            epoch_acc = float(running_corrects.cpu()) / dataset_sizes[phase]\n",
    "\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                'phase', epoch_loss, epoch_acc))\n",
    "#             print (int(running_corrects.cpu()))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "        scheduler.step(epoch_loss)\n",
    "        for param_group in optimizer.param_groups:\n",
    "          print(param_group['lr'])\n",
    "\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [01:54<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0053 Acc: 0.9391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:17<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0078 Acc: 0.9162\n",
      "0.0005\n",
      "Epoch 1/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [01:55<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0051 Acc: 0.9405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:17<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0070 Acc: 0.9303\n",
      "0.0005\n",
      "Epoch 2/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [01:55<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0045 Acc: 0.9488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:17<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0072 Acc: 0.9295\n",
      "0.0005\n",
      "Epoch 3/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [01:55<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0041 Acc: 0.9519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:17<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0071 Acc: 0.9284\n",
      "0.0005\n",
      "Epoch 4/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 453/453 [01:56<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0040 Acc: 0.9543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 80/80 [00:17<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase Loss: 0.0068 Acc: 0.9319\n",
      "0.0005\n",
      "Training complete in 11m 5s\n",
      "Best val Acc: 0.931898\n"
     ]
    }
   ],
   "source": [
    "model_conv = train_model(model_conv, {'train':train_loader, 'val':val_loader}, dataset_sizes, criterion, optimizer_conv, exp_lr_scheduler, True,\n",
    "                     num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_path = 'C:\\Users\\rohit\\VirtualEnv'\n",
    "torch.save(model_conv.state_dict(), 'resnet152.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test1_model(model, dataloaders, optimizer, use_gpu):\n",
    "    model.train(False)\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    for data in tqdm(dataloaders):\n",
    "        inputs = data\n",
    "        if use_gpu:\n",
    "            inputs = Variable(inputs.cuda())\n",
    "        else:\n",
    "            inputs = Variable(inputs)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        predictions.append(preds)\n",
    "        #labels.append(labels_)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 229/229 [00:48<00:00,  4.56it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions2 = test1_model(model_conv, test_dataloader, optimizer_conv, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions3 = torch.cat(predictions2)\n",
    "predictions3 = np.array(predictions3.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7301"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 2, 5], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions3[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv('resnet50_15_col.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7301"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['label'] = predictions3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name  label\n",
       "0      3.jpg      5\n",
       "1      5.jpg      0\n",
       "2      6.jpg      4\n",
       "3     11.jpg      4\n",
       "4     14.jpg      5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('torch_resnet152.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
